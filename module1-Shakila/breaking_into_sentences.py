import re
import os
from sinling import SinhalaTokenizer, POSTagger

def preprocess_file(input_path, output_path):
    with open(input_path, 'r', encoding='utf-8') as file:
        document = file.read()
        print("\nüîπ Original Input Text:\n")
        print(document)

    tokenizer = SinhalaTokenizer()
    tagger = POSTagger()

    tokenized_sentences = tokenizer.split_sentences(document)
    text = ' '.join(s.strip() for s in tokenized_sentences)

    tagged_sentences = []
    pronouns = []

    for sentence in tokenized_sentences:
        tokens = tokenizer.tokenize(sentence)
        tagged = tagger.predict([tokens])
        tagged_sentences.append(tagged[0])
        for word, tag in tagged[0]:
            if tag == 'PRP':
                pronouns.append(word)

    print("Pronouns (PRP) found in text:")
    print(set(pronouns))

    # Normalize whitespace
    text = re.sub(r'\s+', ' ', text)

    # Step 1: Add full stop after common verbs
    text = re.sub(r'(\S*‡∂±‡∑Ä‡∑è)(?=\s+(?!(‡∂±‡∂∏‡∑ä|‡∂±‡∂Ç|‡∂∏‡∑ö ‡∂ß‡∑í‡∂ö))[^.])', r'\1. ', text)
    text = re.sub(r'(?<!\S)(‡∂∂‡∂Ω‡∂±‡∑ä‡∂±)(?=\s|$)', r'\1. ', text)
    text = re.sub(r'(?<!\S)(‡∂ö‡∑í‡∂∫‡∂Ω|‡∂ö‡∑í‡∂∫‡∂Ω‡∑è)(?=\s|$)', r'\1. ', text)
    text = re.sub(r'(‡∂ú‡∂∏‡∑î)(?=\s+(?!‡∂∏‡∑ö ‡∂ß‡∑í‡∂ö)\S|$)', r'\1. ', text)
    text = re.sub(r'(‡∂∏‡∑ö ‡∂ß‡∑í‡∂ö)(?=\s|$)', r'\1. ', text)
    text = re.sub(r'(‡∑Ä‡∑í‡∂Ø‡∑í‡∂∫\s+‡∂∂‡∂Ω‡∂∏‡∑î)(?=\s|$)', r'\1. ', text)

    # Step 2: Remove incorrect full stops between phrases
    text = re.sub(r'(‡∂¥‡∑ö‡∂±‡∑Ä‡∑è)\.\s*(‡∂á‡∂≠‡∑í)', r'\1 \2', text)
    text = re.sub(r'(‡∂ö‡∑í‡∂∫‡∂Ω|‡∂ö‡∑í‡∂∫‡∂Ω‡∑è)\.\s*(‡∂Ø‡∑î‡∂±\S*)', r'\1 \2', text)
    text = re.sub(r'(‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑ä‡∂±‡∑ô)\.\s*(‡∂í‡∂ö‡∂ß)', r'\1 \2', text)
    text = re.sub(r'(‡∂∏‡∑ú‡∂ö‡∂Ø)\.\s*', r'\1 ', text)

    # Step 3: Full stop before pronoun + ‡∂Ø‡∑ê‡∂±‡∑ä
    pronoun_group_escaped = '|'.join(re.escape(p) for p in sorted(set(pronouns), key=len, reverse=True))
    pattern_before = rf'(?<![.\n])\s*({pronoun_group_escaped})\s+(‡∂Ø‡∑ê‡∂±‡∑ä)'
    text = re.sub(pattern_before, r'. \1 \2', text)

    # Step 4: Full stop before "‡∂Ø‡∑ê‡∂±‡∑ä" if not preceded by a pronoun or keyword
    keywords = ["‡∂í‡∂ö‡∂ß", "‡∂â‡∂≠‡∑í‡∂±‡∑ä", "‡∂ë‡∑Ñ‡∑ô‡∂±‡∂∏‡∑ä", "‡∂ä‡∑Ö‡∂ü‡∂ß", "‡∂í‡∑Ä‡∂ú‡∑ö‡∂∏", "‡∂í ‡∑Ä‡∂ú‡∑ö‡∂∏", "‡∂ë‡∂≠‡∂ö‡∑ú‡∂ß", "‡∂ä‡∑ä‡∂ß", "‡∂í‡∑Ä‡∑è", "‡∂ä‡∂ß ‡∂¥‡∑É‡∑ä‡∑É‡∑ö"]
    avoid_before_dan = set(pronouns + keywords)
    negative_lookbehinds = ''.join(rf'(?<!{re.escape(w)})' for w in avoid_before_dan)
    pattern_before_dan = rf'(?<!\.){negative_lookbehinds}\s+(‡∂Ø‡∑ê‡∂±‡∑ä)'
    text = re.sub(pattern_before_dan, r'. \1', text)

    # Step 5: Full stop before listed keywords
    for kw in keywords:
        pattern = rf'(?<!\.)\s*({re.escape(kw)})'
        text = re.sub(pattern, r'. \1', text)

    # Step X: Add full stop after "‡∂±‡∑ä‡∂±" cases
    text = re.sub(
        r'(\S*[^‡∑ô]‡∂±‡∑ä‡∂±)(?=\s+(?!(‡∑Ä‡∑í‡∂Ø‡∑í‡∑Ñ|‡∂≠‡∑í‡∂∫‡∂±‡∑ä‡∂±|‡∂¥‡∑î‡∑Ö‡∑î‡∑Ä‡∂±‡∑ä|‡∂∂‡∑ê‡∂ª‡∑í|‡∂±‡∂∏‡∑ä|‡∂ú‡∑í‡∂∫|‡∂ö‡∂Ω‡∑í‡∂±‡∑ä))\S)',
        r'\1. ',
        text
    )
    text = re.sub(
        r'(\S*[^‡∑ô]‡∂±‡∑ä‡∂±)\.\s+(‡∂ï‡∂±‡∑í(?: ‡∂±‡∑ë)?)',
        r'\1 \2. ',
        text
    )

    # Final steps: Split, filter, and write
    sentences = [s.strip() for s in text.split('.') if s.strip()]
    filtered_sentences = [s for s in sentences if len(s.split()) > 2]
    final_text = '. '.join(filtered_sentences) + '.'

    print("\nüîπ Final Processed Output Text:\n")
    print(final_text)

    with open(output_path, 'w', encoding='utf-8') as out_file:
        out_file.write(final_text)

    print(f"‚úÖ Preprocessing complete. Output saved to: {output_path}")
